{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorrect-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cordless-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom I/O functions\n",
    "def read_labels(filename):\n",
    "    \"\"\"\n",
    "    Reads the labels.csv file containing info on\n",
    "    which samples contain SAS or not\n",
    "\n",
    "    Input: \n",
    "        filename: file path to labels.csv\n",
    "    Output:\n",
    "        y: a numpy array of labels \"Yes\" vs \"No\"\n",
    "    \"\"\"\n",
    "\n",
    "    y = pd.read_csv(filename)\n",
    "    y = y.sort_values(by=\"indices\").reset_index(drop=True).to_numpy()\n",
    "\n",
    "    return y\n",
    "\n",
    "def read_samples(files, filePath):\n",
    "    \"\"\"\n",
    "    Read in the output files from SA.wrapper.r\n",
    "    and save it as a compressed file using numpy\n",
    "    \n",
    "    Input:\n",
    "        files: an iterable of names that indicate which output\n",
    "        files to read; len(samples) must be greater than or equal to one\n",
    "        \n",
    "        filePath: path to the folder containing all output files\n",
    "        \n",
    "    Output:\n",
    "        a numpy ndarray of all output files concatenated together\n",
    "    \"\"\"\n",
    "\n",
    "    iterator = iter(files)\n",
    "    missing = []\n",
    "    # grab the first output data and use it as a baseline\n",
    "    firstFile = next(iterator)\n",
    "    fileStart = os.path.join(filePath, firstFile)\n",
    "    X = pd.read_table(fileStart, header=None).to_numpy()\n",
    "    rows, columns = X.shape\n",
    "\n",
    "    # We now concatenate all samples together\n",
    "    # Note: THIS COULD TAKE A WHILE! (only run once)\n",
    "    start = time.time()\n",
    "    for fileName in iterator:\n",
    "        fullPath = os.path.join(filePath, fileName)\n",
    "        if not os.path.exists(fullPath):\n",
    "            missing.append(fileName)\n",
    "            continue\n",
    "\n",
    "        sample = pd.read_table(fullPath, header=None).to_numpy()\n",
    "        X = np.concatenate((X, sample), axis=0)\n",
    "    end = time.time()\n",
    "    print('Time taken to concatenate files:', end - start)\n",
    "\n",
    "    # reshape to samples, rows, columns\n",
    "    X = X.reshape(-1, rows, columns)\n",
    "\n",
    "    return X, missing\n",
    "\n",
    "def clean_data(X, y, threshold):\n",
    "    \"\"\"\n",
    "    Ensure no element is nan or infinity, otherwise scikit-learn \n",
    "    will not like that.\n",
    "    \n",
    "    If samples with nan or infinity is below a threshold amount of the \n",
    "    total data/samples in X, then we drop them\n",
    "    \n",
    "    Input: \n",
    "        X: a three dimensional numpy array\n",
    "            + Assume first dimension = # of samples\n",
    "            + Assume second dimension = # of rows in each sample\n",
    "            + Assume third dimension = # of columns in each sample\n",
    "        y: the corresponding label values for X\n",
    "        \n",
    "    Output:\n",
    "        X_clean: X cleaned if mising data is below threshold, otherwise X\n",
    "        y_clean: y cleaned if missing data is below threshold, otherwise y\n",
    "        samples_clean: number of samples left after cleaning (max is X.shape[0])\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(X.shape) == 3\n",
    "    assert y.shape[0] == X.shape[0]\n",
    "    samples = X.shape[0]\n",
    "    print(\"Dected\", samples, \"samples total\")\n",
    "\n",
    "    has_NAN = np.any(np.isnan(X))\n",
    "    samples_with_nans = set()\n",
    "    if has_NAN:\n",
    "        print(\"We got NaNs, identifying location of NaNs...\")\n",
    "        indices_nan = np.argwhere(np.isnan(X))\n",
    "        samples_with_nans.update(set(indices_nan[:, 0]))\n",
    "        columns_with_nans = set(indices_nan[:, 2])\n",
    "        print(f\"Attributes with NaNs are: {columns_with_nans}\")\n",
    "        # print(f\"Samples with NaNs are: {samples_with_nans}\")\n",
    "        print(f\"There are \", len(samples_with_nans), \" Samples with NANs\")\n",
    "\n",
    "    has_Inf = np.any(np.isinf(X))\n",
    "    samples_with_Infs = set()\n",
    "    if has_Inf:\n",
    "        print(\"We got Infinities, identifying location of Infs...\")\n",
    "        indices_Infs = np.argwhere(np.isinf(X))\n",
    "        samples_with_Infs.update(set(indices_Infs[:, 0]))\n",
    "        columns_with_Infs = set(indices_Infs[:, 2])\n",
    "        print(f\"Attributes with Infs are: {columns_with_Infs}\")\n",
    "        # print(f\"Samples with Infs are: {samples_with_nans}\")\n",
    "        print(f\"There are \", len(samples_with_Infs), \" Samples with Infs\")\n",
    "\n",
    "    # Attempting to clean the dataset from NaNs and Infs\n",
    "    bug_samples = set()\n",
    "    bug_samples.update(samples_with_nans)\n",
    "    bug_samples.update(samples_with_Infs)\n",
    "    print(f\"There are a total of {len(bug_samples)} containing Infs or NaNs\")\n",
    "    bug_sample_l = list(bug_samples)\n",
    "    bug_sample_l.sort()\n",
    "    print(\"Deleting samples \", bug_sample_l)\n",
    "\n",
    "    if len(bug_samples) < threshold*samples:\n",
    "        print(f\"Less than {threshold*100}% of Samples, dropping...\")\n",
    "        X_clean = np.delete(X, bug_sample_l, axis = 0)\n",
    "        y_clean = np.delete(y, bug_sample_l, axis = 0)\n",
    "        samples_clean = samples - len(bug_sample_l)\n",
    "        print(f\"After dropping, we have {samples_clean} samples left\")\n",
    "    else:\n",
    "        print(\"Too many Samples to drop, can't clean!\")\n",
    "        \n",
    "    return X_clean, y_clean, samples_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-vertex",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "We first read in training samples using an iterable of filenames and 'compress' down to one dimesnion using `reshape` so that RandomForest can evaluate it correctly\n",
    "\n",
    "The training samples consist of a 50-50 split betwee neutral samples and SAS samples of shape (160, 2) per sample. \n",
    "I choose the 50-50 ratio because **class imabalnce** is often a big headache in model fitting and for the sake of training, a 50-50 split will best enable the classifier to capture the signals of SAS. \n",
    "\n",
    "The attribute key is as belows:\n",
    "\n",
    "1. Maximum fst in a 2.5 rho window\n",
    "2. Mean-squared error for the highest fst peak in a window\n",
    "\n",
    "`y` will contain label information for if sample i has SAS or not of shape (# of samples, 1) with one aitribute:\n",
    "\n",
    "1. SAS (Yes or No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optimum-viewer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'Yes']\n",
      " [2 'Yes']\n",
      " [3 'Yes']\n",
      " [4 'No']\n",
      " [5 'No']]\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = read_labels(\"./GenInput/input/label.csv\")\n",
    "print(y_train[:5])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "democratic-miller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to concatenate files: 21.189603328704834\n",
      "[]\n",
      "(10000, 2)\n",
      "(10000, 160, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39257336, 0.14608226],\n",
       "       [0.23921614, 0.0362196 ],\n",
       "       [0.39257336, 0.1809441 ],\n",
       "       [0.35295858, 0.15712493],\n",
       "       [0.35295858, 0.19305147],\n",
       "       [0.24498803, 0.05261772],\n",
       "       [0.24498803, 0.0496599 ],\n",
       "       [0.24498803, 0.0707043 ],\n",
       "       [0.24498803, 0.05170502],\n",
       "       [0.24498803, 0.06001001]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator, actual cost = O(1)\n",
    "files = (\"output_\" + str(i) for i in range(1, 10000+1))\n",
    "filePath = \"./GenInput/output\"\n",
    "\n",
    "X_train, missing = read_samples(files, filePath)\n",
    "print(missing)\n",
    "\n",
    "missing_indices = [int(m[7:]) for m in missing]\n",
    "if len(missing_indices):\n",
    "    y_train = np.delete(y_train, missing_indices, axis=0)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "X_train[0][:10, ] # check first 10 rows of first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "retained-purse",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dected 10000 samples total\n",
      "There are a total of 0 containing Infs or NaNs\n",
      "Deleting samples  []\n",
      "Less than 1.0% of Samples, dropping...\n",
      "After dropping, we have 10000 samples left\n",
      "2626 samples did not meet expectations\n",
      "(7374, 160, 2)\n",
      "(7374, 2)\n",
      "[[0.19143744 0.03973952]\n",
      " [0.23921614 0.04675881]\n",
      " [0.23921614 0.07185455]\n",
      " [0.23921614 0.09208617]\n",
      " [0.18027272 0.04922432]\n",
      " [0.18027272 0.06475553]\n",
      " [0.23921614 0.10787962]\n",
      " [0.23921614 0.07205316]\n",
      " [0.23921614 0.07087022]\n",
      " [0.23921614 0.09739757]\n",
      " [0.41272825 0.41429405]\n",
      " [0.43028743 0.48100667]\n",
      " [0.43028743 0.48729017]\n",
      " [0.43028743 0.51805551]\n",
      " [0.43028743 0.46599337]\n",
      " [0.35548305 0.30120695]\n",
      " [0.19143744 0.03796099]\n",
      " [0.19143744 0.03513313]\n",
      " [0.19143744 0.03064425]\n",
      " [0.19143744 0.0649706 ]\n",
      " [0.19143744 0.07321033]\n",
      " [0.19143744 0.06874646]\n",
      " [0.23921614 0.09006451]\n",
      " [0.30728549 0.16032256]\n",
      " [0.30728549 0.24950303]\n",
      " [0.23575881 0.08410037]\n",
      " [0.23575881 0.07868783]\n",
      " [0.23575881 0.09500625]\n",
      " [0.30728549 0.16419137]\n",
      " [0.30728549 0.16225767]\n",
      " [0.30728549 0.17585   ]\n",
      " [0.30728549 0.12608914]\n",
      " [0.30728549 0.16424731]\n",
      " [0.24498803 0.09222503]\n",
      " [0.23921614 0.09204819]\n",
      " [0.19143744 0.04761077]\n",
      " [0.15603293 0.02264162]\n",
      " [0.23021936 0.06980907]\n",
      " [0.24498803 0.087633  ]\n",
      " [0.23021936 0.09260321]\n",
      " [0.29154519 0.11656227]\n",
      " [0.28921628 0.13129981]\n",
      " [0.28921628 0.10685659]\n",
      " [0.28921628 0.15069657]\n",
      " [0.28921628 0.09840249]\n",
      " [0.28921628 0.12819338]\n",
      " [0.34910714 0.17848952]\n",
      " [0.28921628 0.13805236]\n",
      " [0.34910714 0.18625175]\n",
      " [0.28921628 0.1192572 ]\n",
      " [0.28921628 0.08735462]\n",
      " [0.28921628 0.10100786]\n",
      " [0.28921628 0.10051619]\n",
      " [0.28921628 0.1026813 ]\n",
      " [0.28921628 0.10696572]\n",
      " [0.28921628 0.11902564]\n",
      " [0.28921628 0.08534757]\n",
      " [0.28921628 0.1247649 ]\n",
      " [0.19143744 0.05019999]\n",
      " [0.19143744 0.04311238]\n",
      " [0.19143744 0.03752668]\n",
      " [0.19143744 0.0408551 ]\n",
      " [0.19143744 0.02804366]\n",
      " [0.19143744 0.04183987]\n",
      " [0.19143744 0.03673341]\n",
      " [0.19143744 0.04446961]\n",
      " [0.14764031 0.01899309]\n",
      " [0.14764031 0.02159281]\n",
      " [0.14764031 0.01738293]\n",
      " [0.14764031 0.02143772]\n",
      " [0.14764031 0.01666825]\n",
      " [0.10734694 0.01019995]\n",
      " [0.14764031 0.02137413]\n",
      " [0.19143744 0.04261917]\n",
      " [0.19143744 0.03191125]\n",
      " [0.14764031 0.02859659]\n",
      " [0.21570737 0.06953786]\n",
      " [0.21570737 0.07235954]\n",
      " [0.21570737 0.07009865]\n",
      " [0.21570737 0.05806407]\n",
      " [0.14764031 0.02047255]\n",
      " [0.10734694 0.00813429]\n",
      " [0.10734694 0.01268359]\n",
      " [0.10734694 0.01065224]\n",
      " [0.14764031 0.01914955]\n",
      " [0.14764031 0.02501804]\n",
      " [0.14764031 0.02401362]\n",
      " [0.14764031 0.02758392]\n",
      " [0.14764031 0.02223791]\n",
      " [0.14764031 0.02198433]\n",
      " [0.14764031 0.02098067]\n",
      " [0.14764031 0.0185234 ]\n",
      " [0.14764031 0.02521926]\n",
      " [0.14764031 0.02755039]\n",
      " [0.10734694 0.01161774]\n",
      " [0.19579406 0.04564877]\n",
      " [0.19143744 0.05385913]\n",
      " [0.19143744 0.04999925]\n",
      " [0.19143744 0.05554058]\n",
      " [0.19143744 0.04505515]\n",
      " [0.19143744 0.04883516]\n",
      " [0.17752169 0.04176275]\n",
      " [0.19143744 0.03713869]\n",
      " [0.19143744 0.05637454]\n",
      " [0.19143744 0.04526894]\n",
      " [0.10734694 0.01243338]\n",
      " [0.10734694 0.01030339]\n",
      " [0.10734694 0.00911794]\n",
      " [0.14764031 0.01742857]\n",
      " [0.19143744 0.03890372]\n",
      " [0.19143744 0.03941553]\n",
      " [0.23921614 0.06427307]\n",
      " [0.10734694 0.00645329]\n",
      " [0.10734694 0.01005668]\n",
      " [0.10734694 0.00958853]\n",
      " [0.10734694 0.006383  ]\n",
      " [0.10734694 0.00656749]\n",
      " [0.10734694 0.01290305]\n",
      " [0.11040492 0.0109037 ]\n",
      " [0.18027272 0.0229095 ]\n",
      " [0.18027272 0.03736921]\n",
      " [0.18027272 0.03996084]\n",
      " [0.18027272 0.05020898]\n",
      " [0.10734694 0.01207772]\n",
      " [0.10734694 0.01286557]\n",
      " [0.11356486 0.01061135]\n",
      " [0.14764031 0.01737029]\n",
      " [0.19143744 0.05148217]\n",
      " [0.30524078 0.13920077]\n",
      " [0.30524078 0.1520938 ]\n",
      " [0.21570737 0.06376963]\n",
      " [0.21570737 0.06135122]\n",
      " [0.13041364 0.02081223]\n",
      " [0.10734694 0.00865647]\n",
      " [0.13041364 0.01232799]\n",
      " [0.13041364 0.01618662]\n",
      " [0.13041364 0.01689895]\n",
      " [0.19143744 0.03431639]\n",
      " [0.16465535 0.03582991]\n",
      " [0.29154519 0.10163536]\n",
      " [0.10734694 0.00878226]\n",
      " [0.10734694 0.00696347]\n",
      " [0.10734694 0.00589324]\n",
      " [0.10734694 0.0068117 ]\n",
      " [0.10734694 0.00598699]\n",
      " [0.10734694 0.0100499 ]\n",
      " [0.10734694 0.00783619]\n",
      " [0.10734694 0.00716115]\n",
      " [0.10734694 0.00868428]\n",
      " [0.10734694 0.00875939]\n",
      " [0.10734694 0.00785562]\n",
      " [0.10734694 0.00910165]\n",
      " [0.10734694 0.00521439]\n",
      " [0.10734694 0.01026073]\n",
      " [0.10734694 0.0084065 ]\n",
      " [0.14764031 0.02617029]\n",
      " [0.14764031 0.0220728 ]\n",
      " [0.14764031 0.02577997]\n",
      " [0.10734694 0.01066064]\n",
      " [0.15603293 0.01999975]]\n",
      "[[3 'Yes']\n",
      " [5 'No']\n",
      " [6 'No']\n",
      " [7 'Yes']\n",
      " [8 'Yes']\n",
      " [9 'No']\n",
      " [10 'No']\n",
      " [13 'Yes']\n",
      " [14 'No']\n",
      " [15 'No']\n",
      " [16 'Yes']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'No']\n",
      " [20 'No']\n",
      " [21 'Yes']\n",
      " [23 'Yes']\n",
      " [24 'Yes']\n",
      " [26 'Yes']\n",
      " [27 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "X_clean, y_clean, samples_clean = clean_data(X_train, y_train, threshold=0.01)\n",
    "\n",
    "toDrop = []\n",
    "for i in range(0, X_clean.shape[0]):\n",
    "    sample = X_clean[i, :]\n",
    "    # 1. Fst must be between 0 to 1.0\n",
    "    minFst, maxFst = min(sample[:, 0]), max(sample[:, 1])\n",
    "    # 2. MSE must be between 0 to 1.0 \n",
    "    minMSE, maxMSE = min(sample[:, 1]), max(sample[:, 1])\n",
    "    # 3. the mean squared error should almost always be smaller than the maximum Fst \n",
    "    if (minFst < 0 or maxFst > 1.0 or \n",
    "        minMSE < 0 or minFst > 1.0 or \n",
    "        sum(sample[:, 1] <= maxMSE) != sample.shape[0]\n",
    "       ):\n",
    "        toDrop.append(i)\n",
    "print(len(toDrop), \"samples did not meet expectations\")\n",
    "X_clean, y_clean = np.delete(X_clean, toDrop, axis=0), np.delete(y_clean, toDrop, axis=0)\n",
    "print(X_clean.shape)\n",
    "print(y_clean.shape)\n",
    "\n",
    "print(X_clean[0, :, :])\n",
    "print(y_clean[:20, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pediatric-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result into a numpy object\n",
    "np.savez_compressed('./data/train.npz', \n",
    "                    X_train=X_clean, y_train=y_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-david",
   "metadata": {},
   "source": [
    "## Small Test Data Batch\n",
    "\n",
    "I then asked the simulation for a 50-50 split, 1000 sample test set that's not used in the model building process at all for an earnest attempt at out-of-sample prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-significance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'Yes']\n",
      " [2 'No']\n",
      " [3 'Yes']\n",
      " [4 'Yes']\n",
      " [5 'Yes']]\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test = read_labels(\"./GenInputTest/input/label.csv\")\n",
    "print(y_test[:5])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attended-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to concatenate files: 0.7271561622619629\n",
      "[]\n",
      "(1000, 2)\n",
      "[[1 'Yes']\n",
      " [2 'No']\n",
      " [3 'Yes']\n",
      " [4 'Yes']\n",
      " [5 'Yes']\n",
      " [6 'Yes']\n",
      " [7 'No']\n",
      " [8 'No']\n",
      " [9 'No']\n",
      " [10 'Yes']\n",
      " [11 'Yes']\n",
      " [12 'Yes']\n",
      " [13 'Yes']\n",
      " [14 'Yes']\n",
      " [15 'No']\n",
      " [16 'No']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'Yes']\n",
      " [20 'No']]\n",
      "(1000, 160, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.43241981, 0.26219987],\n",
       "       [0.43241981, 0.32465513],\n",
       "       [0.35295858, 0.24039368],\n",
       "       [0.43241981, 0.31260821],\n",
       "       [0.43241981, 0.3246583 ],\n",
       "       [0.43241981, 0.39181164],\n",
       "       [0.43241981, 0.40586182],\n",
       "       [0.43241981, 0.39830596],\n",
       "       [0.43241981, 0.43595325],\n",
       "       [0.43241981, 0.37849837]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator, actual cost = O(1)\n",
    "files = (\"output_\" + str(i) for i in range(1, 1000+1))\n",
    "filePath = \"./GenInputTest/output\"\n",
    "\n",
    "X_test, missing = read_samples(files, filePath)\n",
    "print(missing)\n",
    "\n",
    "missing_indices = [int(m[7:]) for m in missing]\n",
    "if len(missing_indices):\n",
    "    y_test = np.delete(y_test, missing_indices, axis=0)\n",
    "print(y_test.shape)\n",
    "print(y_test[:20, :])\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test[0][:10, ] # check first 10 rows of first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "overall-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dected 1000 samples total\n",
      "There are a total of 0 containing Infs or NaNs\n",
      "Deleting samples  []\n",
      "Less than 1.0% of Samples, dropping...\n",
      "After dropping, we have 1000 samples left\n",
      "\n",
      "\n",
      "(1000, 160, 2)\n",
      "(1000, 2)\n",
      "264 samples did not meet expectations\n",
      "(736, 160, 2)\n",
      "(736, 2)\n",
      "[[0.2549095  0.08516194]\n",
      " [0.2549095  0.0837489 ]\n",
      " [0.2549095  0.08440095]\n",
      " [0.35548305 0.15999598]\n",
      " [0.28921628 0.10953766]\n",
      " [0.28921628 0.10241462]\n",
      " [0.28921628 0.11529185]\n",
      " [0.23021936 0.0553937 ]\n",
      " [0.23921614 0.0545814 ]\n",
      " [0.23921614 0.0509845 ]\n",
      " [0.23921614 0.06241661]\n",
      " [0.23921614 0.0737488 ]\n",
      " [0.10734694 0.00863988]\n",
      " [0.19143744 0.04645035]\n",
      " [0.22997152 0.04599871]\n",
      " [0.19143744 0.04506182]\n",
      " [0.19143744 0.03975318]\n",
      " [0.19143744 0.04393289]\n",
      " [0.28921628 0.11273935]\n",
      " [0.22997152 0.05295682]\n",
      " [0.14460059 0.02191636]\n",
      " [0.14460059 0.02033399]\n",
      " [0.2549095  0.0882787 ]\n",
      " [0.23921614 0.06258111]\n",
      " [0.23921614 0.06837051]\n",
      " [0.23921614 0.07826347]\n",
      " [0.23921614 0.06478117]\n",
      " [0.2549095  0.07740275]\n",
      " [0.34910714 0.13749933]\n",
      " [0.48341837 0.39286456]\n",
      " [0.48341837 0.37216905]\n",
      " [0.35295858 0.23704285]\n",
      " [0.23921614 0.07343324]\n",
      " [0.24498803 0.06008032]\n",
      " [0.14764031 0.01974779]\n",
      " [0.14764031 0.01856077]\n",
      " [0.14764031 0.01947275]\n",
      " [0.19143744 0.04980163]\n",
      " [0.23921614 0.07326976]\n",
      " [0.23921614 0.06107669]\n",
      " [0.19143744 0.04230937]\n",
      " [0.19143744 0.05624539]\n",
      " [0.10734694 0.00693547]\n",
      " [0.13041364 0.01369499]\n",
      " [0.13041364 0.01907127]\n",
      " [0.14764031 0.01656109]\n",
      " [0.13041364 0.01441739]\n",
      " [0.23921614 0.04788152]\n",
      " [0.13041364 0.01478297]\n",
      " [0.23921614 0.05849452]\n",
      " [0.23921614 0.06108355]\n",
      " [0.24498803 0.06128547]\n",
      " [0.24498803 0.0609206 ]\n",
      " [0.29154519 0.09546671]\n",
      " [0.24498803 0.06515442]\n",
      " [0.28921628 0.13219082]\n",
      " [0.28921628 0.14400667]\n",
      " [0.2549095  0.08733064]\n",
      " [0.2549095  0.08325973]\n",
      " [0.2549095  0.09014893]\n",
      " [0.2549095  0.08413876]\n",
      " [0.31822093 0.14290054]\n",
      " [0.31822093 0.15398795]\n",
      " [0.32312523 0.145812  ]\n",
      " [0.32312523 0.15607871]\n",
      " [0.39257336 0.2366692 ]\n",
      " [0.30728549 0.11649112]\n",
      " [0.30728549 0.12026723]\n",
      " [0.32312523 0.11475689]\n",
      " [0.32312523 0.12335273]\n",
      " [0.2549095  0.07554506]\n",
      " [0.2549095  0.07076097]\n",
      " [0.2549095  0.0752467 ]\n",
      " [0.2549095  0.09094169]\n",
      " [0.10734694 0.00951   ]\n",
      " [0.14764031 0.01856787]\n",
      " [0.14764031 0.01670029]\n",
      " [0.17752169 0.03111107]\n",
      " [0.10734694 0.00651593]\n",
      " [0.15603293 0.01935976]\n",
      " [0.19143744 0.03992849]\n",
      " [0.19143744 0.05058405]\n",
      " [0.13041364 0.02292065]\n",
      " [0.13041364 0.02178919]\n",
      " [0.15603293 0.02781609]\n",
      " [0.15603293 0.02658511]\n",
      " [0.15603293 0.01999285]\n",
      " [0.10734694 0.00585034]\n",
      " [0.10734694 0.00474173]\n",
      " [0.15603293 0.01830117]\n",
      " [0.15603293 0.01346346]\n",
      " [0.10734694 0.01225127]\n",
      " [0.15603293 0.01146005]\n",
      " [0.15603293 0.01404396]\n",
      " [0.10734694 0.00297298]\n",
      " [0.15603293 0.02116547]\n",
      " [0.15603293 0.02174518]\n",
      " [0.15603293 0.02001052]\n",
      " [0.15603293 0.01549242]\n",
      " [0.15603293 0.01412816]\n",
      " [0.19143744 0.03113939]\n",
      " [0.23921614 0.05428395]\n",
      " [0.23921614 0.06999232]\n",
      " [0.23921614 0.05451205]\n",
      " [0.15603293 0.01623762]\n",
      " [0.15603293 0.01120871]\n",
      " [0.15603293 0.02007849]\n",
      " [0.14764031 0.01976613]\n",
      " [0.10734694 0.00595499]\n",
      " [0.15603293 0.01717225]\n",
      " [0.10734694 0.00868196]\n",
      " [0.16465535 0.0325645 ]\n",
      " [0.16465535 0.03797793]\n",
      " [0.12517359 0.02123362]\n",
      " [0.15603293 0.02777534]\n",
      " [0.10744475 0.01008903]\n",
      " [0.15603293 0.02211472]\n",
      " [0.1611245  0.02585421]\n",
      " [0.15603293 0.02231806]\n",
      " [0.10734694 0.01063733]\n",
      " [0.13041364 0.00926792]\n",
      " [0.15603293 0.0180236 ]\n",
      " [0.10734694 0.00475355]\n",
      " [0.18027272 0.03888754]\n",
      " [0.18027272 0.02823629]\n",
      " [0.18027272 0.03783827]\n",
      " [0.18027272 0.03686783]\n",
      " [0.15603293 0.01913569]\n",
      " [0.28106509 0.07221755]\n",
      " [0.28106509 0.07924711]\n",
      " [0.23921614 0.06224227]\n",
      " [0.23921614 0.05450591]\n",
      " [0.23921614 0.06202141]\n",
      " [0.23921614 0.05551141]\n",
      " [0.23921614 0.06872365]\n",
      " [0.29154519 0.11080892]\n",
      " [0.23921614 0.07736887]\n",
      " [0.23921614 0.05804609]\n",
      " [0.23921614 0.05408498]\n",
      " [0.23921614 0.06864118]\n",
      " [0.23921614 0.06080918]\n",
      " [0.1611245  0.02353469]\n",
      " [0.14764031 0.01660911]\n",
      " [0.14764031 0.01915902]\n",
      " [0.17752169 0.03383656]\n",
      " [0.17752169 0.03442112]\n",
      " [0.14764031 0.01328306]\n",
      " [0.14764031 0.01658598]\n",
      " [0.10734694 0.00981133]\n",
      " [0.14764031 0.02128365]\n",
      " [0.14764031 0.01954641]\n",
      " [0.14764031 0.01480624]\n",
      " [0.10734694 0.00551432]\n",
      " [0.14764031 0.01241007]\n",
      " [0.14764031 0.01292044]\n",
      " [0.14764031 0.01935002]\n",
      " [0.14764031 0.01535225]\n",
      " [0.14764031 0.01207118]\n",
      " [0.14764031 0.01319725]\n",
      " [0.14764031 0.012497  ]]\n",
      "[[2 'No']\n",
      " [4 'Yes']\n",
      " [5 'Yes']\n",
      " [6 'Yes']\n",
      " [7 'No']\n",
      " [8 'No']\n",
      " [10 'Yes']\n",
      " [11 'Yes']\n",
      " [12 'Yes']\n",
      " [13 'Yes']\n",
      " [14 'Yes']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'Yes']\n",
      " [20 'No']\n",
      " [21 'Yes']\n",
      " [24 'Yes']\n",
      " [25 'No']\n",
      " [26 'No']\n",
      " [28 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "X_test_clean, y_test_clean, samples_test = clean_data(\n",
    "    X_test, y_test, threshold=0.01)\n",
    "print(\"\\n\")\n",
    "print(X_test_clean.shape)\n",
    "print(y_test_clean.shape)\n",
    "\n",
    "toDrop = []\n",
    "for i in range(0, X_test_clean.shape[0]):\n",
    "    sample = X_test_clean[i, :]\n",
    "    # 1. Fst must be between 0 to 1.0\n",
    "    minFst, maxFst = min(sample[:, 0]), max(sample[:, 1])\n",
    "    # 2. MSE must be between 0 to 1.0 \n",
    "    minMSE, maxMSE = min(sample[:, 1]), max(sample[:, 1])\n",
    "    # 3. the mean squared error should almost always be smaller than the maximum Fst \n",
    "    if (minFst < 0 or maxFst > 1.0 or \n",
    "        minMSE < 0 or minFst > 1.0 or \n",
    "        sum(sample[:, 1] <= maxMSE) != sample.shape[0]\n",
    "       ):\n",
    "        toDrop.append(i)\n",
    "print(len(toDrop), \"samples did not meet expectations\")\n",
    "X_test_clean, y_test_clean = np.delete(X_test_clean, toDrop, axis=0), np.delete(y_test_clean, toDrop, axis=0)\n",
    "print(X_test_clean.shape)\n",
    "print(y_test_clean.shape)\n",
    "\n",
    "print(X_test_clean[0, :, :])\n",
    "print(y_test_clean[:20, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "commercial-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result into a numpy object\n",
    "np.savez_compressed('./data/test.npz', X_test=X_test_clean, y_test=y_test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-minutes",
   "metadata": {},
   "source": [
    "# New Wrapper Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emerging-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'Yes']\n",
      " [2 'Yes']\n",
      " [3 'No']\n",
      " [4 'Yes']\n",
      " [5 'Yes']\n",
      " [6 'Yes']\n",
      " [7 'No']\n",
      " [8 'Yes']\n",
      " [9 'Yes']\n",
      " [10 'No']\n",
      " [11 'Yes']\n",
      " [12 'No']\n",
      " [13 'No']\n",
      " [14 'No']\n",
      " [15 'No']\n",
      " [16 'No']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'No']\n",
      " [20 'No']]\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "y_trainNew = read_labels(\"./GenInput-New/input/label.csv\")\n",
    "print(y_trainNew[:20])\n",
    "print(y_trainNew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "completed-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to concatenate files: 17.11920404434204\n",
      "['output_3829', 'output_5012', 'output_6767', 'output_7500']\n",
      "(9996, 2)\n",
      "(9996, 160, 2)\n",
      "[[1 'Yes']\n",
      " [2 'Yes']\n",
      " [3 'No']\n",
      " [4 'Yes']\n",
      " [5 'Yes']\n",
      " [6 'Yes']\n",
      " [7 'No']\n",
      " [8 'Yes']\n",
      " [9 'Yes']\n",
      " [10 'No']\n",
      " [11 'Yes']\n",
      " [12 'No']\n",
      " [13 'No']\n",
      " [14 'No']\n",
      " [15 'No']\n",
      " [16 'No']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'No']\n",
      " [20 'No']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.75204082, 0.45297954],\n",
       "       [0.75204082, 0.47820333],\n",
       "       [0.6513074 , 0.44110209],\n",
       "       [0.60207931, 0.34496555],\n",
       "       [0.75204082, 0.57374648],\n",
       "       [0.61255874, 0.29727373],\n",
       "       [0.72495782, 0.44813823],\n",
       "       [0.72495782, 0.44213076],\n",
       "       [0.72495782, 0.46751836],\n",
       "       [0.72495782, 0.42472071]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator, actual cost = O(1)\n",
    "files = (\"output_\" + str(i) for i in range(1, 10000+1))\n",
    "filePath = \"./GenInput-New/output\"\n",
    "\n",
    "X_trainNew, missing = read_samples(files, filePath)\n",
    "print(missing)\n",
    "\n",
    "missing_indices = [int(m[7:]) for m in missing]\n",
    "if len(missing_indices):\n",
    "    y_trainNew = np.delete(y_trainNew, missing_indices, axis=0)\n",
    "print(y_trainNew.shape)\n",
    "print(X_trainNew.shape)\n",
    "print(y_trainNew[:20])\n",
    "X_trainNew[0][:10, ] # check first 10 rows of first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fourth-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dected 9996 samples total\n",
      "There are a total of 0 containing Infs or NaNs\n",
      "Deleting samples  []\n",
      "Less than 1.0% of Samples, dropping...\n",
      "After dropping, we have 9996 samples left\n",
      "234 samples did not meet expectations\n",
      "(9762, 160, 2)\n",
      "(9762, 2)\n",
      "[[0.75204082 0.45297954]\n",
      " [0.75204082 0.47820333]\n",
      " [0.6513074  0.44110209]\n",
      " [0.60207931 0.34496555]\n",
      " [0.75204082 0.57374648]\n",
      " [0.61255874 0.29727373]\n",
      " [0.72495782 0.44813823]\n",
      " [0.72495782 0.44213076]\n",
      " [0.72495782 0.46751836]\n",
      " [0.72495782 0.42472071]\n",
      " [0.72495782 0.45195588]\n",
      " [0.49499908 0.22298095]\n",
      " [0.39257336 0.11362164]\n",
      " [0.6193874  0.28290537]\n",
      " [0.6193874  0.29256814]\n",
      " [0.6193874  0.31693046]\n",
      " [0.6193874  0.26537553]\n",
      " [0.6193874  0.32437042]\n",
      " [0.6193874  0.27831314]\n",
      " [0.6193874  0.33846372]\n",
      " [0.6193874  0.2612371 ]\n",
      " [0.6193874  0.29883278]\n",
      " [0.6193874  0.29729131]\n",
      " [0.6193874  0.42116566]\n",
      " [0.6193874  0.37249489]\n",
      " [0.6193874  0.35469922]\n",
      " [0.6193874  0.36377075]\n",
      " [0.6193874  0.36798763]\n",
      " [0.39257336 0.1849375 ]\n",
      " [0.6193874  0.3275587 ]\n",
      " [0.6193874  0.33868092]\n",
      " [0.6193874  0.31811667]\n",
      " [0.6193874  0.31781156]\n",
      " [0.23921614 0.03575121]\n",
      " [0.6193874  0.50130616]\n",
      " [0.6193874  0.37165985]\n",
      " [0.6193874  0.3171473 ]\n",
      " [0.6193874  0.28273084]\n",
      " [0.72495782 0.51710589]\n",
      " [0.6193874  0.26490468]\n",
      " [0.6193874  0.28855291]\n",
      " [0.6193874  0.40184353]\n",
      " [0.6193874  0.38959393]\n",
      " [0.6193874  0.37415834]\n",
      " [0.6193874  0.36899399]\n",
      " [0.6193874  0.30402203]\n",
      " [0.85621302 0.61857303]\n",
      " [0.85621302 0.72575257]\n",
      " [0.49499908 0.15828858]\n",
      " [0.43028743 0.12924773]\n",
      " [0.56242497 0.24973543]\n",
      " [0.6193874  0.27887558]\n",
      " [0.6193874  0.37773722]\n",
      " [0.48341837 0.21019054]\n",
      " [0.6193874  0.26956953]\n",
      " [0.6193874  0.34813417]\n",
      " [0.6193874  0.36998456]\n",
      " [0.56242497 0.25593706]\n",
      " [0.6193874  0.25003827]\n",
      " [0.56242497 0.23639001]\n",
      " [0.29154519 0.05837688]\n",
      " [0.72495782 0.60590365]\n",
      " [0.60207931 0.26832216]\n",
      " [0.60207931 0.35860968]\n",
      " [0.61255874 0.35602518]\n",
      " [0.52071006 0.26904251]\n",
      " [0.85621302 0.69234895]\n",
      " [0.23021936 0.01793358]\n",
      " [0.85621302 0.63126314]\n",
      " [0.6193874  0.24184685]\n",
      " [0.6193874  0.31161473]\n",
      " [0.49499908 0.17749008]\n",
      " [0.6193874  0.33609356]\n",
      " [0.52071006 0.22391317]\n",
      " [0.52071006 0.26958094]\n",
      " [0.52071006 0.24598166]\n",
      " [0.52071006 0.27985413]\n",
      " [0.49499908 0.23659712]\n",
      " [0.72495782 0.4059882 ]\n",
      " [0.35295858 0.08012849]\n",
      " [0.49499908 0.29922923]\n",
      " [0.31822093 0.08191507]\n",
      " [0.49499908 0.22210856]\n",
      " [0.30728549 0.05612448]\n",
      " [0.35295858 0.10297221]\n",
      " [0.401053   0.14433522]\n",
      " [0.52071006 0.2000913 ]\n",
      " [0.52071006 0.20386679]\n",
      " [0.35295858 0.10084418]\n",
      " [0.35295858 0.0980479 ]\n",
      " [0.35295858 0.09108273]\n",
      " [0.35295858 0.10183074]\n",
      " [0.35295858 0.08682655]\n",
      " [0.35295858 0.12297029]\n",
      " [0.35295858 0.13796442]\n",
      " [0.35295858 0.09333675]\n",
      " [0.28106509 0.06648997]\n",
      " [0.15603293 0.01786701]\n",
      " [0.23021936 0.04449016]\n",
      " [0.4020901  0.11208866]\n",
      " [0.4020901  0.10119944]\n",
      " [0.4020901  0.10458587]\n",
      " [0.30728549 0.047957  ]\n",
      " [0.30728549 0.06048609]\n",
      " [0.18027272 0.019376  ]\n",
      " [0.15603293 0.01153024]\n",
      " [0.10614296 0.00325701]\n",
      " [0.19143744 0.02645472]\n",
      " [0.19143744 0.02328528]\n",
      " [0.19143744 0.02155831]\n",
      " [0.19143744 0.01118481]\n",
      " [0.15603293 0.00794405]\n",
      " [0.23921614 0.025844  ]\n",
      " [0.23921614 0.03498989]\n",
      " [0.23921614 0.03140267]\n",
      " [0.23921614 0.03320234]\n",
      " [0.23921614 0.04451728]\n",
      " [0.23921614 0.04078455]\n",
      " [0.23921614 0.02412559]\n",
      " [0.23921614 0.0414741 ]\n",
      " [0.23921614 0.04307316]\n",
      " [0.23921614 0.04227613]\n",
      " [0.22997152 0.03483233]\n",
      " [0.28106509 0.05810791]\n",
      " [0.28106509 0.0461036 ]\n",
      " [0.28106509 0.05345096]\n",
      " [0.19143744 0.02101769]\n",
      " [0.15603293 0.01189117]\n",
      " [0.19143744 0.01618344]\n",
      " [0.19143744 0.0170205 ]\n",
      " [0.19143744 0.01714282]\n",
      " [0.19143744 0.02320311]\n",
      " [0.19143744 0.01948712]\n",
      " [0.15603293 0.00889161]\n",
      " [0.19143744 0.02285116]\n",
      " [0.19143744 0.01852983]\n",
      " [0.19143744 0.01723536]\n",
      " [0.15603293 0.01530823]\n",
      " [0.15603293 0.02054216]\n",
      " [0.15603293 0.01411601]\n",
      " [0.18027272 0.02333811]\n",
      " [0.14764031 0.0102298 ]\n",
      " [0.15603293 0.01249906]\n",
      " [0.28106509 0.05489544]\n",
      " [0.28106509 0.0460501 ]\n",
      " [0.28106509 0.07578464]\n",
      " [0.14764031 0.01296753]\n",
      " [0.10734694 0.00240296]\n",
      " [0.18027272 0.01743131]\n",
      " [0.18027272 0.0230982 ]\n",
      " [0.12517359 0.00618214]\n",
      " [0.17752169 0.02228748]\n",
      " [0.18027272 0.01823411]\n",
      " [0.23021936 0.04647075]\n",
      " [0.17560907 0.01496312]\n",
      " [0.23021936 0.02896604]\n",
      " [0.17560907 0.02138692]\n",
      " [0.30728549 0.07519533]\n",
      " [0.30728549 0.06743243]\n",
      " [0.18027272 0.02494289]]\n",
      "[[1 'Yes']\n",
      " [2 'Yes']\n",
      " [3 'No']\n",
      " [4 'Yes']\n",
      " [5 'Yes']\n",
      " [6 'Yes']\n",
      " [7 'No']\n",
      " [9 'Yes']\n",
      " [10 'No']\n",
      " [11 'Yes']\n",
      " [12 'No']\n",
      " [13 'No']\n",
      " [14 'No']\n",
      " [15 'No']\n",
      " [17 'Yes']\n",
      " [18 'Yes']\n",
      " [19 'No']\n",
      " [20 'No']\n",
      " [21 'Yes']\n",
      " [22 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "# clean data of Inf and Nans\n",
    "X_cleanNew, y_cleanNew, samples_clean = clean_data(X_trainNew, y_trainNew, threshold=0.01)\n",
    "# clean data that does NOT meet expectations\n",
    "toDrop = []\n",
    "for i in range(0, X_cleanNew.shape[0]):\n",
    "    sample = X_cleanNew[i, :]\n",
    "    # 1. Fst must be between 0 to 1.0\n",
    "    minFst, maxFst = min(sample[:, 0]), max(sample[:, 1])\n",
    "    # 2. MSE must be between 0 to 1.0 \n",
    "    minMSE, maxMSE = min(sample[:, 1]), max(sample[:, 1])\n",
    "    # 3. the mean squared error should almost always be smaller than the maximum Fst \n",
    "    if (minFst < 0 or maxFst > 1.0 or \n",
    "        minMSE < 0 or minFst > 1.0 or \n",
    "        sum(sample[:, 1] <= maxMSE) != sample.shape[0]\n",
    "       ):\n",
    "        toDrop.append(i)\n",
    "print(len(toDrop), \"samples did not meet expectations\")\n",
    "X_cleanNew, y_cleanNew = np.delete(X_cleanNew, toDrop, axis=0), np.delete(y_cleanNew, toDrop, axis=0)\n",
    "print(X_cleanNew.shape)\n",
    "print(y_cleanNew.shape)\n",
    "\n",
    "print(X_cleanNew[0, :, :])\n",
    "print(y_cleanNew[:20, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result into a numpy object\n",
    "np.savez_compressed('./data/trainNew.npz', \n",
    "                    X_train=X_cleanNew, y_train=y_cleanNew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
