{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "victorian-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olive-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom I/O functions\n",
    "def read_labels(filename):\n",
    "    # read in label data\n",
    "    y_dir = \"./Generate_Training_Data/output/label.csv\"\n",
    "    y = pd.read_csv(filename)\n",
    "    y = y.sort_values(by = \"indices\").drop(\"indices\", axis=1).to_numpy()\n",
    "\n",
    "    return y\n",
    "\n",
    "def read_samples(samples, fileStart, filepath, keep_col=None):\n",
    "    # read in training data\n",
    "    # take = 251 # row 1 to row 251 (exclusive), 250 rows\n",
    "    X_dir_first = \"./Generate_Training_Data/output/output_1\"\n",
    "    X = pd.read_table(fileStart).to_numpy()\n",
    "    if keep_col is not None:\n",
    "        # keep columns from 1:keep_col\n",
    "        X = X[:, keep_col]\n",
    "    rows, columns = X.shape\n",
    "\n",
    "    # We now concatenate all samples together\n",
    "    # Note: THIS COULD TAKE A WHILE! (only run once)\n",
    "    start = time.time()\n",
    "    for i in range(2, samples+1):\n",
    "        filename = \"./Generate_Training_Data/output/output_\" + str(i)\n",
    "        sample = pd.read_table(filename).to_numpy()[:, keep_col]\n",
    "        X = np.concatenate((X, sample), axis=0)\n",
    "    end = time.time()\n",
    "    print('Time taken to concatenate files:', end - start)\n",
    "\n",
    "    # reshape to samples, rows, columns\n",
    "    X = X.reshape(-1, rows, columns)\n",
    "\n",
    "    return X\n",
    "\n",
    "def clean_data(X, y, samples):\n",
    "    \"\"\"\n",
    "    House keeping: ensure no element is nan or infinity, otherwise scikit-learn\n",
    "    will not like that\n",
    "    X Must be have 3 dimensions ONLY (otherwise indices are not accurate)\n",
    "    \"\"\"\n",
    "    assert len(X.shape) == 3\n",
    "    assert samples == X.shape[0]\n",
    "\n",
    "    has_NAN = np.any(np.isnan(X))\n",
    "    if has_NAN:\n",
    "        print(\"We got NaNs, identifying location of NaNs...\")\n",
    "        indices_nan = np.argwhere(np.isnan(X))\n",
    "        samples_with_nans = set(indices_nan[:, 0])\n",
    "        columns_with_nans = set(indices_nan[:, 2])\n",
    "        print(f\"Attributes with NaNs are: {columns_with_nans}\")\n",
    "        # print(f\"Samples with NaNs are: {samples_with_nans}\")\n",
    "        print(f\"There are \", len(samples_with_nans), \" Samples with NANs\")\n",
    "\n",
    "    has_Inf = np.any(np.isinf(X))\n",
    "    if has_Inf:\n",
    "        print(\"We got Infinities, identifying location of Infs...\")\n",
    "        indices_Infs = np.argwhere(np.isinf(X))\n",
    "        samples_with_Infs = set(indices_Infs[:, 0])\n",
    "        columns_with_Infs = set(indices_Infs[:, 2])\n",
    "        print(f\"Attributes with Infs are: {columns_with_Infs}\")\n",
    "        # print(f\"Samples with Infs are: {samples_with_nans}\")\n",
    "        print(f\"There are \", len(samples_with_Infs), \" Samples with Infs\")\n",
    "\n",
    "    # Attempting to clean the dataset from NaNs and Infs\n",
    "    bug_samples = set()\n",
    "    bug_samples.update(samples_with_nans)\n",
    "    bug_samples.update(samples_with_Infs)\n",
    "    print(f\"There are a total of {len(bug_samples)} containing Infs or NaNs\")\n",
    "\n",
    "    threshold = 0.5\n",
    "    if len(bug_samples) < threshold*samples:\n",
    "        print(f\"Less than {threshold*100}% of Samples, dropping.\")\n",
    "        X_clean = np.delete(X, list(bug_samples), axis = 0)\n",
    "        y_clean = np.delete(y, list(bug_samples), axis = 0)\n",
    "        samples_clean = samples - len(bug_samples)\n",
    "        print(f\"After dropping, we have {samples_clean} samples left\")\n",
    "    else:\n",
    "        print(\"Too many Samples to drop, can't clean!\")\n",
    "        \n",
    "    return X_clean, y_clean, samples_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-remove",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "We first read in `samples` training samples and 'compress' down to one dimesnion using `reshape` so that RandomForest can evaluate it correctly\n",
    "\n",
    "The training samples consist of a 50-50 split betwee neutral samples and SAS samples of shape (460, 15) per sample. \n",
    "I choose the 50-50 ratio because **class imabalnce** is often a big headache in model fitting and for the sake of training, a 50-50 split will best enable the classifier to capture the signals of SAS. \n",
    "\n",
    "The attribute key is as belows:\n",
    "\n",
    "1. Genetic diversity on the X (Pi_X)\n",
    "2. Genetic diversity on the Y (Pi_Y) \n",
    "3. Total genetic diversity (Pi_tot)\n",
    "4. Fst between the X and Y\n",
    "5. Dxy between the X and Y\n",
    "6. Da between the X and Y\n",
    "7. Tajima's D on the X\n",
    "8. Tajima's D on the Y\n",
    "9. Tajima's D across all samples\n",
    "10. Relative density of SNPs on the X\n",
    "11. Relative density of SNPs on the Y\n",
    "12. Relative density of SNPS across all samples\n",
    "13. Average correlation between SNPs on X\n",
    "14. Average correlation between SNPs on Y\n",
    "15. Average correlation between SNPs across all samples\n",
    "\n",
    "`y` will contain label information for if sample i has SAS or not of shape (`samples`, 1) with one aitribute:\n",
    "\n",
    "1. SAS (Yes or No)\n",
    "\n",
    "Then, we flatten both `X` and `y` to be of shape (samples, 460*15 = 6900) and (samples,) respectively\n",
    "\n",
    "## Caution\n",
    "\n",
    "Attribute 12-15 has been Dropped due to presence of NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "earned-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train = 10000\n",
    "y_train = read_labels(\"./Generate_Training_Data/input/label.csv\")\n",
    "print(y_train[:5])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forty-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to concatenate files: 311.31700110435486\n",
      "[[4.87912088e-02 8.46244879e-02 4.35141923e-01 ... 2.67642073e-04\n",
      "  5.44662309e-04 1.58810825e-03]\n",
      " [4.55037920e-02 2.80023335e-02 4.64400840e-01 ... 9.81354269e-04\n",
      "  5.44662309e-04 4.51022742e-03]\n",
      " [6.71747607e-02 4.93341360e-02 4.33266278e-01 ... 1.15978232e-03\n",
      "  8.16993464e-04 3.93850845e-03]\n",
      " ...\n",
      " [2.55639098e-01 2.42819155e-01 2.94519141e-01 ... 1.15978232e-03\n",
      "  1.27087872e-03 1.20696227e-03]\n",
      " [2.73940345e-01 2.23941739e-01 2.90598291e-01 ... 1.78428049e-03\n",
      "  1.99709513e-03 1.77868123e-03]\n",
      " [1.74978867e-01 1.69601905e-01 1.95907501e-01 ... 1.42742439e-03\n",
      "  1.54320988e-03 1.65163258e-03]]\n",
      "(10000, 460, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train = read_samples(samples_train, \n",
    "                      \"./Generate_Training_Data/output/output_1\", \n",
    "                      \"./Generate_Training_Data/output/output_\", \n",
    "                      keep_col=list(range(0, 12)))\n",
    "print(X_train[0, :, :])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fiscal-spiritual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got NaNs, identifying location of NaNs...\n",
      "Attributes with NaNs are: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
      "There are  3210  Samples with NANs\n",
      "We got Infinities, identifying location of Infs...\n",
      "Attributes with Infs are: {7}\n",
      "There are  731  Samples with Infs\n",
      "There are a total of 3500 containing Infs or NaNs\n",
      "Less than 50.0% of Samples, dropping.\n",
      "After dropping, we have 6500 samples left\n",
      "\n",
      "\n",
      "(6500, 460, 12)\n",
      "(6500, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_clean, y_train_clean, samples_train = clean_data(\n",
    "    X_train, y_train, samples_train)\n",
    "print(\"\\n\")\n",
    "print(X_train_clean.shape)\n",
    "print(y_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interesting-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result into a numpy object\n",
    "np.savez_compressed('./data/train.npz', \n",
    "                    X_train=X_train_clean, y_train=y_train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-sample",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "I then asked the simulation for a 80-20 split, 1000 sample test set that's not used in the model building process at all for an earnest attempt at out-of-sample prediction error.\n",
    "\n",
    "## Caution\n",
    "\n",
    "Attribute 12-15 has been Dropped due to presence of NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "diagnostic-insert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Yes']\n",
      " ['Yes']\n",
      " ['No']\n",
      " ['No']\n",
      " ['Yes']]\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "samples_test = 1000\n",
    "y_test = read_labels(\"./Generate_Test_Data/input/label.csv\")\n",
    "print(y_test[:5])\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "blessed-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to concatenate files: 3.7436068058013916\n",
      "[[0.0782967  0.05133263 0.45040038 ... 0.00115246 0.00069284 0.00391538]\n",
      " [0.03285659 0.04828878 0.470051   ... 0.00189818 0.00200154 0.01082169]\n",
      " [0.13103352 0.04828986 0.47686226 ... 0.01403295 0.00230947 0.01288814]\n",
      " ...\n",
      " [0.19491035 0.21330522 0.21085953 ... 0.00101688 0.00107775 0.00103323]\n",
      " [0.15855573 0.13472918 0.15447927 ... 0.00074571 0.00061586 0.00076132]\n",
      " [0.19194139 0.20391443 0.20721044 ... 0.00067792 0.00092379 0.00081571]]\n",
      "(1000, 460, 12)\n"
     ]
    }
   ],
   "source": [
    "X_test = read_samples(samples_test, \n",
    "                      \"./Generate_Test_Data/output/output_1\", \n",
    "                      \"./Generate_Test_Data/output/output_\", \n",
    "                      keep_col=list(range(0, 12)))\n",
    "print(X_test[0, :, :])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pending-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got NaNs, identifying location of NaNs...\n",
      "Attributes with NaNs are: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n",
      "There are  321  Samples with NANs\n",
      "We got Infinities, identifying location of Infs...\n",
      "Attributes with Infs are: {7}\n",
      "There are  85  Samples with Infs\n",
      "There are a total of 353 containing Infs or NaNs\n",
      "Less than 50.0% of Samples, dropping.\n",
      "After dropping, we have 647 samples left\n",
      "\n",
      "\n",
      "(647, 460, 12)\n",
      "(647, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_clean, y_test_clean, samples_test = clean_data(\n",
    "    X_test, y_test, samples_test)\n",
    "print(\"\\n\")\n",
    "print(X_test_clean.shape)\n",
    "print(y_test_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dominant-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result into a numpy object\n",
    "np.savez_compressed('./data/test.npz', X_test=X_test_clean, y_test=y_test_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
